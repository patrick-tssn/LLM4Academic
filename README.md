# LLM4Academic

LLM4Academic is a repository for everything I want to know about large language models (LLMs). There are two parts in this repository: (1) Theory: reading list, survey, curated sources; (2) Practice: insightful experiment, demo, framework.

> *"**In theory, theory and practice are the same. In practice, they are not**."*

**Table of Contents**

- [Theory](#theory)

  - [Datasets](#datasets)
  - [Open Source LLM](#open-source-llms)
  - [Evaluation](#evaluation)
- [Practice](#Practice)

  - [API](#api)
  - [Instruction Tuning](#instruction-tuning)

## Theory

### Reading List


### Datasets

Datasets for Pretrain/Finetune/Instruction-tune LLMs, see [Datasets](Theory/Dataset.md) for details.

### Open Source LLMs

Collection of various open-source LLMs, see [Open Souce LLMs](Theory/OpenSourceLLM.md) for details.

### Evaluation

- [AlpacaEval](https://tatsu-lab.github.io/alpaca_eval/) | comprehensive
- [HELM](https://github.com/stanford-crfm/helm) | comprehensive
- [AGIEval](https://github.com/microsoft/AGIEval) | comprehensive
- [C-Eval](https://github.com/SJTU-LIT/ceval) | comprehensive, Chinese
- [SuperCLUE](https://github.com/CLUEbenchmark/SuperCLUE) | comprehensive, Chinese
- [LM-Evaluation-Harness](https://github.com/EleutherAI/lm-evaluation-harness) | safety
- [Safety-Prompts](https://github.com/thu-coai/Safety-Prompts) | safety
- [LaMP](https://lamp-benchmark.github.io/) | personalization

## Practice

### API

LLM API demos, see [API](Practice/API/README.md) for details.

### Instruction Tuning

Instruction Tuning on 4 LLM with multilingual instructions, see [Instruction Tuning](Practice/Instruction_Tuning/READEME.md) for details.
